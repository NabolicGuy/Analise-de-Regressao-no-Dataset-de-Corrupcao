# An√°lise de Regress√£o no Dataset de Corrup√ß√£o 

Este documento descreve **exatamente o que foi feito** no notebook `corrupcao_from_Priek.ipynb`, que replica a ordem e a l√≥gica do *PrieKaue (1).ipynb* aplicadas ao arquivo **`corrupcao.csv`**.

---

## 1) Contexto e objetivo
Modelar o **`Corrupcao_Valor_Perdido`** a partir de vari√°veis econ√¥micas e institucionais usando:
- **Regress√£o Linear (OLS)** como baseline;
- **Regress√£o Polinomial (grau 2)**;
- **Sele√ß√£o de vari√°veis via Backward Elimination** (Œ± = 0,05).

---

## 2) Vis√£o do dataset
- **Tamanho:** 100 linhas √ó 11 colunas
- **Vari√°veis num√©ricas (exemplos):** `Orcamento_Total`, `Salario_Medio_Func`, `Numero_Fiscalizacoes`, `Contratos_Publicos`, `Indice_Transparencia`, `Corrupcao_Valor_Perdido` (alvo)
- **Vari√°veis categ√≥ricas (exemplos):** `Partido_Governo`, `Midia_Livre`, `Judiciario_Atuante`, `Cultura_Corrupcao`, `Investigacoes_Federais`

---

## 3) O que foi feito (passo a passo)

### 3.1 Diagn√≥stico inicial
- `df.info()` e `df.head()`
- **Contagem de valores √∫nicos** por coluna
- **Mapa de nulos** (visual)
- **Histogramas** das vari√°veis num√©ricas

### 3.2 Tratamento de dados
- Valores **negativos** nas colunas num√©ricas relevantes ‚Üí convertidos para `NaN`
- **Imputa√ß√£o num√©rica:** mediana
- **Imputa√ß√£o categ√≥rica:** moda
- Checagem final de nulos e **estat√≠sticas p√≥s-tratamento**

### 3.3 Prepara√ß√£o para modelagem
- Convers√£o de categ√≥ricas em **dummies** (`drop_first=True`)
- Garantia de tipos **num√©ricos**
- Defini√ß√£o de `X` e `y` com `y = Corrupcao_Valor_Perdido`
- **Split** treino/teste em 70%/30% (random_state=42)

### 3.4 Regress√£o Linear (OLS) com diagn√≥sticos
- Ajuste por `statsmodels.OLS`
- C√°lculo de **R¬≤ (treino/teste)**
- Testes nos res√≠duos:
  - **Breusch‚ÄìPagan** (heterocedasticidade)
  - **Durbin‚ÄìWatson** (autocorrela√ß√£o)
  - **Shapiro‚ÄìWilk** (normalidade)
- `summary()` completo do modelo

### 3.5 Regress√£o Polinomial (grau 2)
- Gera√ß√£o de *features* com `PolynomialFeatures(degree=2, include_bias=False)`
- Novo ajuste OLS e **mesmos diagn√≥sticos** (R¬≤, BP, DW, Shapiro)
- `summary()` do modelo polinomial

### 3.6 Sele√ß√£o de vari√°veis (*Backward Elimination*)
- Remo√ß√£o iterativa de preditores com p-valor > 0,05 no **treino**
- `summary()` do **modelo final**
- Vers√£o **polinomial** restrita √†s *features* selecionadas e respectivos testes

### 3.7 Gr√°ficos finais (no notebook)
- **Valores Reais vs. Preditos** (teste)
- **Res√≠duos vs. Preditos** (teste)

---

## 4) Principais resultados do run atual

### 4.1 OLS (baseline)
- **R¬≤ treino:** 0,5925  
- **R¬≤ teste:** ‚àí0,2808  ‚Üí *n√£o generaliza* (overfitting / baixo sinal)
- **Breusch‚ÄìPagan (p):** 0,8908 ‚Üí **homoced√°stico**
- **Durbin‚ÄìWatson:** 1,71 ‚Üí leve **autocorrela√ß√£o positiva**
- **Shapiro‚ÄìWilk (p):** 0,9572 ‚Üí res√≠duos **compat√≠veis com normalidade**

### 4.2 Backward Elimination (treino)
- **Qtd. de *features* selecionadas:** 1  
- **Vari√°vel mantida:** `Orcamento_Total`

### 4.3 Polinomial (grau 2) com features selecionadas
- **R¬≤ treino:** 0,5293  
- **R¬≤ teste:** 0,1535  ‚Üí pequena melhoria vs. baseline
- **Breusch‚ÄìPagan (p):** 0,3353 ‚Üí **homoced√°stico**
- **Durbin‚ÄìWatson:** 1,67 ‚Üí leve **autocorrela√ß√£o positiva**
- **Shapiro‚ÄìWilk (p):** 0,4347 ‚Üí res√≠duos **compat√≠veis com normalidade**

> **Leitura geral:** O conjunto de dados √© pequeno e o **sinal preditivo parece concentrado em `Orcamento_Total`**; os demais preditores (incluindo dummies) foram descartados no *backward*. O modelo polinomial com a *feature* selecionada melhora a generaliza√ß√£o (R¬≤_test ‚âà 0,15), mas ainda indica **baixa capacidade explicativa** ‚Äî sugerindo necessidade de novas vari√°veis, transforma√ß√£o/regulariza√ß√£o e/ou aumento de amostra.

---

## 5) Artefatos gerados no notebook
- Tabelas de diagn√≥stico (`info`, `describe`, contagem de √∫nicos)
- Mapa de nulos e histogramas (exibidos inline)
- **Resumos OLS** (`model.summary()`) para os modelos linear e polinomial
- Gr√°ficos: **Reais vs. Preditos** e **Res√≠duos vs. Preditos** (exibidos inline)

---

## Decis√µes e recomenda√ß√µes (o que d√° pra fazer com isso)

**1) Priorizar fiscaliza√ß√£o por or√ßamento (regra simples e pr√°tica).**  
O *backward elimination* manteve apenas **`Orcamento_Total`** como preditor relevante do **`Corrupcao_Valor_Perdido`**. A associa√ß√£o √© **positiva e estatisticamente significativa** (p ‚âà 1.1e-12). No ajuste linear, o coeficiente foi ‚âà **0,0518**: em m√©dia, **cada R$ 1 milh√£o de or√ßamento est√° associado a ~R$ 51,8 mil a mais** de perda estimada por corrup√ß√£o (associa√ß√£o, n√£o causalidade).  
üëâ **Decis√£o pr√°tica:** defina faixas de risco por **quartis de or√ßamento** e **enderece sua capacidade de auditoria** come√ßando pelo topo:

- Q1 (‚âà R$ 44,0 mi): perda estimada ‚âà **R$ 2,06 mi**  
- Q2 (‚âà R$ 50,9 mi): perda estimada ‚âà **R$ 2,42 mi**  
- Q3 (‚âà R$ 56,6 mi): perda estimada ‚âà **R$ 2,72 mi**  
- M√°x. observado (R$ 200 mi): perda estimada ‚âà **R$ 10,15 mi**

> Exemplo de governan√ßa: munic√≠pios/√≥rg√£os **no Q3+** entram em **prioridade alta** com mais amostragens em contratos, *follow-ups* obrigat√≥rios e trilhas de auditoria mais r√≠gidas.

**2) Usar a linha de tend√™ncia como ‚Äúmeta de refer√™ncia‚Äù, n√£o como verdade absoluta.**  
A regress√£o linear sozinha **n√£o generalizou bem** (R¬≤_test < 0). J√° a vers√£o **polinomial com features selecionadas** melhora para **R¬≤_test ‚âà 0,15** ‚Äî ainda baixo.  
üëâ **Decis√£o pr√°tica:** trate o valor previsto como **faixa de refer√™ncia** para metas de redu√ß√£o. Se um √≥rg√£o gastar bem acima do previsto para seu or√ßamento, isso **acende alerta** e justifica auditoria direcionada.

**3) Regras de triagem para aloca√ß√£o de esfor√ßo.**
- **Regra de capacidade:** planejar **n¬∫ de fiscaliza√ß√µes proporcional ao or√ßamento** (ex.: pontos de auditoria por cada R$ 10 mi).  
- **Regra de alerta:** se o **valor perdido observado** ficar **>30‚Äì50%** acima da faixa prevista para aquele or√ßamento, abrir **investiga√ß√£o adicional**.  
- **Regra de acompanhamento:** √≥rg√£os que migram de Q2‚ÜíQ3 no or√ßamento entram automaticamente em **monitoramento refor√ßado** no pr√≥ximo ciclo.

**4) O que *n√£o* d√° pra concluir (e por qu√™).**  
Vari√°veis institucionais/categ√≥ricas (ex.: `Partido_Governo`, `Judiciario_Atuante`, `Midia_Livre`, etc.) **n√£o ficaram no modelo final** nesta amostra. Isso **n√£o comprova** irrelev√¢ncia; pode ser **amostra pequena**, colinearidade com or√ßamento ou codifica√ß√£o simplificada.  
üëâ **Decis√£o pr√°tica:** **n√£o basear pol√≠ticas** apenas nessas categorias **sem mais evid√™ncia**. Se forem estrat√©gicas, coletar dados mais granulares (ex.: tipo de licita√ß√£o, concentra√ß√£o de fornecedores, aditivos, hist√≥rico de san√ß√µes, *red flags* de compras).

**5) Melhorias de dado/modelo que destravam decis√µes mais fortes.**
- **Granularidade de gasto:** separar or√ßamento/perdas por **categoria de despesa/contrato** (obras, sa√∫de, educa√ß√£o‚Ä¶) para a√ß√£o setorial.  
- **Hist√≥rico temporal:** s√©ries mensais/trimestrais para tratar a **autocorrela√ß√£o** (DW ~ 1,7); modelos de painel/tempo tendem a render insights melhores.  
- **Indicadores de integridade:** incluir **red flags** (dispensa recorrente, fornecedor √∫nico, aditivos altos, fatiamento) ‚Äî diretamente acion√°veis.  
- **Regulariza√ß√£o e valida√ß√£o:** Ridge/Lasso + *cross-validation* para reduzir sobreajuste e selecionar vari√°veis de forma mais robusta.

---

## 6) Observa√ß√µes finais
- H√° sinais de **multicolinearidade** em ajustes com muitas *dummies* (condition number alto nos `summary()`).
- A **autocorrela√ß√£o leve** nos res√≠duos (DW ~1,7) merece aten√ß√£o para modelos temporais/espaciais.
- **Pr√≥ximos passos sugeridos:** novas fontes de dados, *feature engineering* dirigido e avalia√ß√£o com regulariza√ß√£o (Ridge/Lasso) e valida√ß√£o cruzada.
